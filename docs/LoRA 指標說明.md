# LoRA 微調指標說明 (Loss & Accuracy)

在訓練過程中，模型每 10 步會輸出一次狀態，最關鍵的是 `loss` (損失值) 和 `token_accuracy` (準確率)。以下用簡單且直觀的方式說明它們的計算方式與意義。

## 1. Token Accuracy (準確率)

**定義**：模型預測每個字（Token）時，猜對的比例。

### 簡單範例

題目：「你叫什麼名字？」
正確答案：「我是 TAIDE」 (共 4 個字)

模型逐字預測結果：
1. 第 1 字應為「我」，模型猜「我」✅ (正確)
2. 第 2 字應為「是」，模型猜「是」✅ (正確)
3. 第 3 字應為「T」，模型猜「G」❌ (錯誤)
4. 第 4 字應為「A」，模型猜「A」✅ (正確)

**計算**：
總共 4 個字，答對 3 個。
$$ \text{Token Accuracy} = \frac{3}{4} = 75\% $$

**你的訓練數據**：
`0.841` (84.1%) 代表每 100 個字中，模型能準確猜對 84 個。這是一個相當高的水準。

---

## 2. Loss (交叉熵損失 Cross-Entropy Loss)

**定義**：衡量模型對正確答案的「信心不足程度」。數值越低越好。

### 簡單範例 (信心分數)

同樣預測「我是 TAIDE」這 4 個字，模型會給出每個字的信心分數（機率）：

1. **「我」**：模型有 **90%** 信心是「我」。
   - Loss = $-\log(0.9) \approx 0.10$ (信心高，扣分少)
2. **「是」**：模型有 **80%** 信心是「是」。
   - Loss = $-\log(0.8) \approx 0.22$
3. **「T」**：模型只有 **30%** 信心是「T」（它可能覺得是 G）。
   - Loss = $-\log(0.3) \approx 1.20$ (信心低，扣分重)
4. **「A」**：模型有 **95%** 信心是「A」。
   - Loss = $-\log(0.95) \approx 0.05$

**計算**：
$$ \text{Average Loss} = \frac{0.10 + 0.22 + 1.20 + 0.05}{4} \approx 0.39 $$

**你的訓練數據**：
`0.5769` 代表模型平均對正確答案的信心約為 $e^{-0.5769} \approx 56\%$。
這意味著模型雖然不總是 100% 確定，但在成千上萬個候選字中，它有超過一半的把握選對正確的字。

---

## 總結

| 指標 | 意義 | 理想趨勢 | 你的數據 (Step ~300) | 評價 |
|------|------|----------|-------------------|------|
| **Loss** | 越低越好 | 📉 持續下降 | **0.5769** | 非常好，收斂快速 |
| **Accuracy** | 越高越好 | 📈 持續上升 | **84.1%** | 很高，模型已掌握回答模式 |
